{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import glob\n",
    "import PIL\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T09:08:45.760459600Z",
     "start_time": "2023-10-03T09:08:42.808628600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "设置随机种子：确保在深度学习任务中的随机性是可重现的。随机性在深度学习中很常见，例如，权重初始化、数据批次的随机抽样、Dropout 等操作都包含了随机性，而设置随机种子可以使这些随机操作在不同运行中产生相同的结果，从而方便调试和比较不同模型的性能。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "bath_size = 8\n",
    "device = 'cuda'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T09:08:45.772453Z",
     "start_time": "2023-10-03T09:08:45.761456900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "鲁棒性：系统在面对不同类型和程度的变化或挑战时能够保持其预期功能或性能。\n",
    "transforms.RandomResizedCrop(224)：在原始图像中随机选择一个矩形区域（裁剪框），这个区域的大小和位置都是随机的。然后，将选定的区域调整为指定的大小（在这里是 224x224 像素）。通常使用双线性插值来进行图像的重新采样，以确保调整后的图像看起来平滑。提高鲁棒性。\n",
    "transforms.RandomHorizontalFlip()：帮助模型学习不同视角下的物体，提高模型的泛化能力。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_dir = './dataset/train/train'\n",
    "test_dir = './dataset/test/test'\n",
    "\n",
    "# glob.glob是用来查找符合特定规则的文件路径名的，跟使用正则表达式的方法很类似\n",
    "train_list = glob.glob(os.path.join(train_dir, '*.jpg'))\n",
    "test_list = glob.glob(os.path.join(test_dir, '*.jpg'))\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T09:08:45.993149300Z",
     "start_time": "2023-10-03T09:08:45.778548100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_list, transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_list[idx]\n",
    "        img = PIL.Image.open(img_path)\n",
    "        label = img_path.split('/')[-1].split('.')[0]\n",
    "        if label == 'train\\\\cat':\n",
    "            label = 0\n",
    "        elif label == 'train\\\\dog':\n",
    "            label = 1\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T09:08:46.006520300Z",
     "start_time": "2023-10-03T09:08:45.993149300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_data = MyDataset(train_list, transform=train_transforms)\n",
    "test_data = MyDataset(test_list, transform=test_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T09:08:46.043285500Z",
     "start_time": "2023-10-03T09:08:46.011502800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=bath_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=bath_size, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T09:08:46.044273700Z",
     "start_time": "2023-10-03T09:08:46.023463200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 构建CNN模型\n",
    "### 卷积层（Convolutional Layer）：\n",
    "卷积核就像一个小窗口在图像上滑动，一次只看一小部分图像（比如5x5像素），然后通过一些数学运算（卷积操作）来检测图像中的特征，比如边缘、纹理等。这一层的目标是捕捉图像的局部信息，通常是一个正方形的矩阵。可以根据希望卷积核捕获的特征尺寸来选择合适的大小。较小的卷积核通常用于捕获局部特征，而较大的卷积核可以捕获更大范围的特征。\n",
    "归一化：nn.BatchNorm2d(16) 表示在神经网络中应用批量归一化层，作用于一个具有 16 个输出通道（特征图）的卷积层或线性层的输出。批量归一化通常紧跟在卷积层或全连接层后面，以确保网络的稳定性和训练效果。\n",
    "激活函数：nn.ReLU(inplace=True) 表示在神经网络中应用 ReLU 激活函数，作用于卷积层或线性层的输出。ReLU 激活函数可以增加网络的非线性特性，从而提高网络的表达能力。将所有负数输入变为零，保持正数输入不变。\n",
    "### 池化层（Pooling Layer）：\n",
    "这一层的任务是缩小图像的尺寸，减少计算量，并且保留最重要的信息。通常，池化层会在卷积层的输出上滑动一个小窗口，然后选择窗口中的最大值（最大池化）或者平均值（平均池化）作为新图像的一部分。这有助于降低图像的维度。\n",
    "### 全连接层（Fully Connected Layer）\n",
    "这一层是CNN的输出层，它将前面的卷积和池化层提取的特征连接在一起，并将它们送入一个神经网络中，用于最终的分类或回归任务。这一层通常包含多个神经元，每个神经元与前一层的所有神经元相连接，因此称为全连接。\n",
    "丢弃层（Dropout Layer）：nn.Dropout 用于在训练过程中随机丢弃一部分神经元的输出，以减少过拟合的风险。参数 0.5 表示丢弃概率为 50%，即每个神经元在前向传播过程中都有 50% 的概率被丢弃。这有助于提高模型的泛化能力。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__() # 调用父类的初始化函数\n",
    "        # 卷积+池化层\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=0), # 3*224*224 -> 16*224*224, stride=2保证卷积核每次移动一个像素, padding=0表示的是在图像周围补0个数,kernel_size=3表示卷积核大小为3*3\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2) # 16*224*224 -> 16*112*112, kernel_size=2表示池化窗口大小为2*2\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=0), # 16*112*112 -> 32*112*112\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2) # 32*112*112 -> 32*56*56\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        # 全连接层\n",
    "        self.fc1 = nn.Linear(3*3*64, 10) # 3*3*64表示输入的特征数，10表示输出的特征数\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(10,2) # 映射到 0/1 两种分类\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    # 调用之前定义的层\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = out.view(out.size(0),-1) # 从多维向量变成一维向量\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T09:08:46.054339300Z",
     "start_time": "2023-10-03T09:08:46.047266100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "CNN(\n  (conv1): Sequential(\n    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv2): Sequential(\n    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv3): Sequential(\n    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc1): Linear(in_features=576, out_features=10, bias=True)\n  (dropout): Dropout(p=0.5, inplace=False)\n  (fc2): Linear(in_features=10, out_features=2, bias=True)\n  (relu): ReLU()\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T09:08:47.977177700Z",
     "start_time": "2023-10-03T09:08:46.058529700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 逻辑回归\n",
    "调整CNN中卷积核权重和偏差，全连接层权重和偏差等"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params=model.parameters(),lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T09:08:48.003431800Z",
     "start_time": "2023-10-03T09:08:47.978410800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义损失函数\n",
    "交叉熵损失函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T09:08:48.035497200Z",
     "start_time": "2023-10-03T09:08:48.004429600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练\n",
    "前向传播: 通过输入数据和模型，计算出预测值\n",
    "反向传播: 通过计算损失函数，计算出梯度\n",
    "为什么要梯度清零: 因为pytorch中梯度是累加的，所以每次反向传播之前都要把梯度清零"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, accuracy:0.6267209053039551, loss:0.6424672603607178\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "for epoch in range(epoch):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    for data, label in train_loader:\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "        optimizer.zero_grad() # 梯度清零\n",
    "        loss.backward() # 反向传播\n",
    "        optimizer.step() # 更新参数\n",
    "\n",
    "        acc = ((output.argmax(dim=1) == label).float().mean())\n",
    "        epoch_accuracy += acc / len(train_loader)\n",
    "        epoch_loss += loss / len(train_loader)\n",
    "\n",
    "    print('Epoch:{}, accuracy:{}, loss:{}'.format(epoch+1,epoch_accuracy,epoch_loss))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-03T09:08:48.008415700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dog_prob = []\n",
    "model.eval() # 模型转换为评估模式\n",
    "with torch.no_grad(): # 在其内部的代码块中禁用梯度计算,在代码块执行结束后梯度计算会重新启用\n",
    "    for data, idx in test_loader:\n",
    "        idx = map(lambda x: x.split('\\\\')[-1], idx)\n",
    "        data = data.to(device)\n",
    "        pred = model(data)\n",
    "        pred_list = F.softmax(pred,dim=1)[:, 1].tolist() # 将模型的输出转化为一个概率分布，确保所有类别的概率之和等于1。也可以用sigmoid。\n",
    "        dog_prob += list(zip(list(idx), pred_list))\n",
    "\n",
    "\n",
    "dog_prob.sort(key = lambda x : int(x[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "idx = list(map(lambda x: x[0], dog_prob))\n",
    "prob = list(map(lambda x: x[1], dog_prob))\n",
    "submission = pd.DataFrame({'id':idx, 'label':prob})\n",
    "submission\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission.to_csv('result.csv', index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(2, 5, figsize=(20,12), facecolor='w')\n",
    "\n",
    "for ax in axis.ravel():\n",
    "    i = random.choice(submission['id'].values)\n",
    "    label = submission.loc[submission['id']==i, 'label'].values[0]\n",
    "    if label > 0.5:\n",
    "        label = 'dog'\n",
    "    else:\n",
    "        label = 'cat'\n",
    "    img_path = os.path.join(test_dir, '{}.jpg'.format(i))\n",
    "    img = PIL.Image.open(img_path)\n",
    "    ax.set_title(label)\n",
    "    ax.imshow(img)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
